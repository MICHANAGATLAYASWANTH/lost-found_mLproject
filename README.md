ğŸ« Campus Lost & Found â€” AutoMatch (Classical ML System)

A complete machine-learningâ€“based Lost & Found item matching system built using ONLY classical ML techniques â€” no deep learning, as required by the project guidelines .

This system automatically matches lost and found item descriptions using:

TF-IDF text vectors

Engineered metadata features

Logistic Regression / RandomForest pairwise classifier

Ranking system with Top-K evaluation

Streamlit UI for user interaction

We built a realistic dataset with metadata, noise, typos, slang, mismatched items, and exact-match pairs.

ğŸ“Œ Project Features

âœ” Automatic match suggestions for lostâ€“found items
âœ” Uses classical ML (TF-IDF + logistic regression / random forest)
âœ” Supports typos, slang, mismatched items, and noisy descriptions
âœ” Includes metadata-based matching (color, brand, location, user, timestamp)
âœ” Fast evaluation using Top-100 TF-IDF prefilter + ML ranking
âœ” Streamlit front-end for demonstration
âœ” High accuracy:

Top-1: 95.02%

Top-3: 99.98%

Top-5: 100%

MRR: 0.9749

ğŸ“‚ Repository Structure
project/
â”‚
â”œâ”€â”€ prepare_pairs.py                   # Builds pairwise training data + TF-IDF
â”œâ”€â”€ train_model.py                     # Trains Logistic Regression + RandomForest
â”œâ”€â”€ evaluate_retrieval_fast.py         # Fast evaluation (Top-100 candidate ranking)
â”‚
â”œâ”€â”€ app_streamlit_model.py             # Streamlit UI using trained model
â”‚
â”œâ”€â”€ lost_found_dataset_realistic_metadata_30k.csv
â”œâ”€â”€ lost_found_exact_match_pairs.csv
â”‚
â”œâ”€â”€ tfidf.joblib                       # Generated TF-IDF vectorizer
â”œâ”€â”€ precomputed_matrices.npz           # Sparse TF-IDF matrix
â”œâ”€â”€ scaler.joblib                      # Feature scaler
â”œâ”€â”€ model_lr.joblib                    # Logistic Regression model
â”œâ”€â”€ model_rf.joblib                    # RandomForest model
â”‚
â””â”€â”€ requirements.txt

ğŸ“˜ Dataset Description

We created a highly realistic dataset with:

âœ” 30,000 total rows (15k lost + 15k found)
âœ” Realistic descriptions containing:

Natural sentences

Typos

Slang (bro, yaar, lol, idk etc.)

Incomplete descriptions

Multi-style language

âœ” Metadata:

item_name

description

color

brand

location

user

timestamp

âœ” Noise & Mismatches

~20% found items are intentional mismatches:

wrong item

wrong color

vague description

unclear details

âœ” Exact-match evaluation file

lost_found_exact_match_pairs.csv contains ground truth lostâ€“found pairs for computing:

Top-K accuracy

MRR

ğŸ§  ML Approach
1ï¸âƒ£ TF-IDF Vectorization

Trained on text_blob

30k max features

Uni/bi-grams

Sparse matrix stored as .npz

2ï¸âƒ£ Feature Engineering

For each (lost, found) pair:

cosine_text (TF-IDF cosine similarity)

jaccard_desc

color_match

brand_match

location_match

user_match

time_diff_hours

len_diff

name_match

3ï¸âƒ£ Supervised Pairwise Classification

Models:

Logistic Regression (LR)

RandomForest (RF)

Both achieved:

ROC AUC: 1.0 (on pairwise task)

(Expected, because strong features + easy negatives)

4ï¸âƒ£ Retrieval Ranking System

For each lost item:

Get Top-100 candidates using TF-IDF cosine

Compute engineered features

Apply trained model

Sort by predicted probability

Evaluate using Top-K metrics

ğŸ“Š Evaluation Results (Fast Ranking)

Using evaluate_retrieval_fast.py, we obtained:

Metric	Score
Top-1 Accuracy	0.9502
Top-3 Accuracy	0.9998
Top-5 Accuracy	1.0000
MRR	0.9749

These results show excellent real-world matching performance.

ğŸš€ Running the Project (Exact Order)
1ï¸âƒ£ Install dependencies
pip install -r requirements.txt

2ï¸âƒ£ Prepare TF-IDF + Pairwise Training Data
python prepare_pairs.py


Outputs:

tfidf.joblib

precomputed_matrices.npz

pairs_train.pkl

3ï¸âƒ£ Train the ML Models
python train_model.py


Outputs:

model_lr.joblib

model_rf.joblib

scaler.joblib

4ï¸âƒ£ Fast Evaluation (Top-K Retrieval)
python evaluate_retrieval_fast.py

5ï¸âƒ£ Run Streamlit App
streamlit run app_streamlit_model.py


Opens UI:

Select lost item â†’ get ranked found matches

Free-text search

View scores, metadata

ğŸ–¥ï¸ Streamlit Demo (Features)

Search lost items

Model-based ranking

Confidence scores

Top results with metadata

Slang + typo handling

Timestamp-based scoring

ğŸ“ Deliverables (as per project PDF)

This project covers every requirement from the official PDF :

âœ” Dataset created
âœ” ML approach with classical models only
âœ” Streamlit-based demonstration
âœ” Ranking evaluation (Top-K, MRR)
âœ” Explanation of features + results
âœ” Source code + README
ğŸ“Œ Potential Future Improvements

Hard negative sampling

Color normalization (navy â†’ blue)

Synonym handling (bottle = flask = tumbler)

Image metadata features (optional per guidelines)

Feedback-based retraining

ANN index (FAISS/Annoy) for ultra-fast retrieval

âœ” Conclusion

This project demonstrates a complete Campus Lost & Found AutoMatch system using classical ML techniques that achieves high accuracy, robustness, and real-world usability, closely following the project guidelines.